{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visuzalize Tensorpack Mask-RCNN Detection Results\n",
    "\n",
    "This notebook visualizes detection results predicted by a trained [Tensorpack Mask-RCNN](https://github.com/tensorpack/tensorpack/tree/master/examples/FasterRCNN) model. \n",
    "\n",
    "This notebook is expected to be run on a Jupyter server running inside the Docker container packaged for Tensorpack Mask-RCNN visualization. The container must be running on an [Amazon EC2 p3.2xlarge instance](https://aws.amazon.com/ec2/instance-types/p3/) launched from [AWS Deep Learning AMI](https://aws.amazon.com/machine-learning/amis/) for Ubuntu.\n",
    "\n",
    "To get started, we set the system path for Python, which assumes that [Tensorpack](https://github.com/tensorpack/tensorpack) is installed under `/tensorpack` in the Docker container containing the server running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import sys\n",
    "\n",
    "sys.path.append('/tensorpack/examples/FasterRCNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling.generalized_rcnn import ResNetFPNModel\n",
    "from config import finalize_configs, config as cfg\n",
    "from eval import predict_image, DetectionResult\n",
    "from dataset import  register_coco\n",
    "from data import get_eval_dataflow\n",
    "\n",
    "from tensorpack.predict.base import OfflinePredictor\n",
    "from tensorpack.tfutils.sessinit import get_model_loader\n",
    "from tensorpack.predict.config import PredictConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we specify the path for the pretrained model used to initialize the RestNet backbone weights. This exmaple assumes the Tensorpack Mask-RCNN model was trained with ResNet 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = \"/data/pretrained-models/ImageNet-R50-AlignPadding.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we initialize the ResNet FPN Tensorpack Mask RCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask r-cnn model\n",
    "mask_rcnn_model = ResNetFPNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we search the directory containing the checkpoints for the trainined model to find the best trained model. In this example, we assume that latest checkpoint is the best trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best pre-trained model checkpoint\n",
    "latest_trained_model = \"\"\n",
    "model_dir=\"/logs\"\n",
    "model_search_path = os.path.join(model_dir, \"model-*.index\" )\n",
    "for model_file in glob.glob(model_search_path):\n",
    "    if model_file > latest_trained_model:\n",
    "        latest_trained_model = model_file\n",
    "\n",
    "trained_model = latest_trained_model[:-6]\n",
    "print(f'Using model: {trained_model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we initialize the model configuration to match the configuration we used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup config\n",
    "cfg.BACKBONE.WEIGHTS = os.path.join(pretrained_model)\n",
    "cfg.MODE_FPN = True\n",
    "cfg.MODE_MASK = True\n",
    "cfg.TEST.RESULT_SCORE_THRESH = cfg.TEST.RESULT_SCORE_THRESH_VIS\n",
    "cfg.DATA.BASEDIR = '/data/'\n",
    "finalize_configs(is_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we register available COCO datasets. In this example we assume that `val2017`dataset is availble and so we create a dataflow from `val2017` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco(cfg.DATA.BASEDIR)\n",
    "df = get_eval_dataflow('coco_val2017')\n",
    "df.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an inference predictor\n",
    "# PredictConfig takes a model, input tensors and output tensors\n",
    "input_tensors = mask_rcnn_model.get_inference_tensor_names()[0]\n",
    "output_tensors = mask_rcnn_model.get_inference_tensor_names()[1]\n",
    "            \n",
    "predictor = OfflinePredictor(PredictConfig(\n",
    "                model=mask_rcnn_model,\n",
    "                session_init=get_model_loader(trained_model),\n",
    "                input_names=input_tensors,\n",
    "                output_names=output_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch the next image available from the dataflow and visualize the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = next(df.get_data())[0]\n",
    "# convert BGR to RGB\n",
    "img = img[:,:,[2,1,0]]\n",
    "fig,ax = plt.subplots(figsize=(img.shape[1]//50, img.shape[0]//50))\n",
    "ax.imshow(img.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use the predictor to get the detection results predicted by our best trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_results = predict_image(img, predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we draw the detection results on our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viz import draw_final_outputs\n",
    "final_viz = draw_final_outputs(img, detection_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we visualize the detection results drawn on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(final_viz.shape[1]//50, final_viz.shape[0]//50))\n",
    "ax.imshow(final_viz.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we repeat the steps for a different image downloaded from the internet, instead of loaded from dataset. One can of course read the image from local path, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "images_path = \"https://i.kinja-img.com/gawker-media/image/upload/c_scale,f_auto,fl_progressive,q_80,w_1600/ekpvcpwo560egadg2mvm.jpg\"\n",
    "img = io.imread(images_path)\n",
    "fig,ax = plt.subplots(figsize=(img.shape[1]//50, img.shape[0]//50))\n",
    "ax.imshow(img.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_results = predict_image(img, predictor)\n",
    "final_viz = draw_final_outputs(img, detection_results)\n",
    "fig,ax = plt.subplots(figsize=(final_viz.shape[1]//50, final_viz.shape[0]//50))\n",
    "ax.imshow(final_viz.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
