---
apiVersion: v1
kind: ConfigMap
metadata:
  name: train-script-{{ .Release.Name }}
data:
  train-script.sh: |
    #!/bin/bash
    
    {{- range .Values.pre_script }}
    {{ . }}
    {{- end }}

    {{- if .Values.git.repo_url }}
    mkdir -p $HOME/tmp/{{ .Release.Name }}
    GIT_CLONE_DIR=$HOME/tmp/{{ .Release.Name }}/$(cat /dev/urandom | tr -dc 'a-z0-9' | fold -w 16 | head -n 1)

    git clone {{ .Values.git.repo_url }} $GIT_CLONE_DIR
    cd $GIT_CLONE_DIR

    {{- if .Values.git.branch }}
    git checkout {{ .Values.git.branch }}
    {{- end }}

    {{- if .Values.git.commit }}
    git fetch origin {{ .Values.git.commit }}
    git reset --hard {{ .Values.git.commit }}
    {{- end }}
    
    {{- end }}
    
    {{- range .Values.train.command }}
    {{ . }} \
    {{- end }}
    {{- range .Values.train.args }}
    {{ . }} \
    {{- end }}
    && echo "Training script done"

    {{- range .Values.post_script }}
    {{ . }}
    {{- end }}

    {{- if .Values.git.repo_url }}
    cd $HOME
    rm -rf $GIT_CLONE_DIR
    {{- end }}
---
apiVersion: kubeflow.org/v2beta1
kind: MPIJob
metadata:
  name: mpijob-{{ .Release.Name }}
  labels:
    app.kubernetes.io/name: {{ .Release.Name }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
spec:
  runPolicy:
    backoffLimit: {{ .Values.backoff_limit }}
    cleanPodPolicy: Running
  mpiImplementation: OpenMPI
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        metadata:
          annotations:
            karpenter.sh/do-not-disrupt: "true"
            sidecar.istio.io/inject: 'false'
            app.kubernetes.io/instance: {{ .Release.Name }}
            app.kubernetes.io/managed-by: {{ .Release.Service }}
        spec:
          restartPolicy: OnFailure
          containers:
          - name: launcher 
            env:
            {{- range $v := .Values.mpirun.env }}
            - name: {{ $v.name }}
              value: "{{ tpl $v.value $ }}"
            {{- end }} 
            command: 
            - mpirun
            args:
            {{- range .Values.mpirun.args }}
            - "{{ tpl .  $ }}"
            {{- end }}
            - /etc/config/train-script.sh
            image: {{ .Values.image }} 
            imagePullPolicy: {{ .Values.image_pull_policy }} 
      
    Worker:
      replicas: {{ .Values.resources.gpu_nodes }}
      template:
        metadata:
          annotations:
            karpenter.sh/do-not-disrupt: "true"
            sidecar.istio.io/inject: 'false'
        spec:
          restartPolicy: Never
          volumes:
          - name: config
            configMap:
              defaultMode: 420
              items:
              - key: train-script.sh
                mode: 365
                path: train-script.sh
              name: train-script-{{ .Release.Name }}
          - name: pv 
            persistentVolumeClaim:
              claimName: {{ .Values.pvc.name }}
          - name: shm
            hostPath:
              path: /dev/shm
              type: Directory
          tolerations:
          - key: "nvidia.com/gpu"
            operator: "Exists"
            effect: "NoSchedule"
          nodeSelector:
            node.kubernetes.io/instance-type: {{ .Values.resources.gpu_instance_type }}
          containers:
          - name: worker
            image: {{ .Values.image }}
            imagePullPolicy: IfNotPresent
            volumeMounts:
            - mountPath: /etc/config
              name: config
            - mountPath: {{ .Values.pvc.mount_path }}
              name: pv
            - mountPath: /dev/shm
              name: shm
            resources:
              requests:
                nvidia.com/gpu: {{ .Values.resources.gpus_per_node }}
              limits:
                nvidia.com/gpu: {{ .Values.resources.gpus_per_node }}
  slotsPerWorker: {{ .Values.resources.gpus_per_node }}
