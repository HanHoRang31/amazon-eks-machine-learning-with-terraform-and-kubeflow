---
apiVersion: v1
kind: ConfigMap
metadata:
  name: train-script-{{ .Release.Name }}
data:
  train-script.sh: |
    #!/bin/bash
  
    {{- if .Values.git.repo_url }}
    mkdir -p $HOME/tmp/{{ .Release.Name }}
    GIT_CLONE_DIR=$HOME/tmp/{{ .Release.Name }}/$(cat /dev/urandom | tr -dc 'a-z0-9' | fold -w 16 | head -n 1)

    git clone {{ .Values.git.repo_url }} $GIT_CLONE_DIR
    cd $GIT_CLONE_DIR

    {{- if .Values.git.branch }}
    git checkout {{ .Values.git.branch }}
    {{- end }}

    {{- if .Values.git.commit }}
    git fetch origin {{ .Values.git.commit }}
    git reset --hard {{ .Values.git.commit }}
    {{- end }}
    
    {{- end }}
     
    {{- range .Values.pre_script }}
    {{ . }}
    {{- end }}

    {{- range .Values.train.command }}
    {{ . }} \
    {{- end }}
    {{- range .Values.train.args }}
    {{ . }} \
    {{- end }}
    && echo "Training script done"

    {{- range .Values.post_script }}
    {{ . }}
    {{- end }}

    {{- if .Values.git.repo_url }}
    cd $HOME
    rm -rf $GIT_CLONE_DIR
    {{- end }}
---
apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: pytorchjob-{{ .Release.Name }}
  labels:
    app.kubernetes.io/name: {{ .Release.Name }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
spec:
  nprocPerNode: "{{ .Values.resources.nproc_per_node }}"
  runPolicy:
    backoffLimit: {{ .Values.backoff_limit }}
    cleanPodPolicy: Running
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        metadata:
          annotations:
            karpenter.sh/do-not-disrupt: "true"
            sidecar.istio.io/inject: 'false'
            app.kubernetes.io/instance: {{ .Release.Name }}
            app.kubernetes.io/managed-by: {{ .Release.Service }}
        spec:
          volumes:
          - name: config
            configMap:
              defaultMode: 420
              items:
              - key: train-script.sh
                mode: 365
                path: train-script.sh
              name: train-script-{{ .Release.Name }}
          - name: shm
            hostPath:
              path: /dev/shm
              type: Directory
          {{- $pv_index := 1 }}
          {{- range $pv := .Values.pvc }}
          - name: pv-{{ $pv_index }}
            persistentVolumeClaim:
              claimName: {{ $pv.name }}
          {{- $pv_index = add $pv_index 1 }}
          {{- end }}
          tolerations:
          {{- range $v := .Values.tolerations }}
            - key: {{ tpl $v.key  $ }}
              {{- if $v.operator }}
              operator: "{{ $v.operator }}"
              {{- end }}
              {{- if $v.effect }}
              effect: "{{ $v.effect }}"
              {{- end }}
          {{- end }} 
          nodeSelector:
            node.kubernetes.io/instance-type: {{ .Values.resources.node_type }}
          containers:
            - name: pytorch
              env:
              {{- range $v := .Values.train.env }}
              - name: {{ $v.name }}
                value: "{{ tpl $v.value $ }}"
              {{- end }} 
              command: 
              - /etc/config/train-script.sh
              resources:
                requests:
                {{- range $k, $v := .Values.resources.requests }}
                  {{ $k }}: {{ $v }}
                {{- end }}
                limits:
                {{- range $k, $v := .Values.resources.limits }}
                  {{ $k }}: {{ $v }}
                {{- end }}
              image: {{ .Values.image }}
              imagePullPolicy: IfNotPresent
              volumeMounts:
                - mountPath: /etc/config
                  name: config
                - mountPath: /dev/shm
                  name: shm
                {{- $pv_index := 1 }}
                {{- range $pv := .Values.pvc }}
                - mountPath: {{ $pv.mount_path }}
                  name: pv-{{ $pv_index }}
                {{- $pv_index = add $pv_index 1 }}
                {{- end }}
    
    {{- if gt (int .Values.resources.nnodes) 1  }}
    Worker:
      replicas: {{ sub .Values.resources.nnodes 1 }}
      restartPolicy: OnFailure
      template:
        metadata:
          annotations:
            karpenter.sh/do-not-disrupt: "true"
            sidecar.istio.io/inject: 'false'
            app.kubernetes.io/instance: {{ .Release.Name }}
            app.kubernetes.io/managed-by: {{ .Release.Service }}
        spec:
          volumes:
          - name: config
            configMap:
              defaultMode: 420
              items:
              - key: train-script.sh
                mode: 365
                path: train-script.sh
              name: train-script-{{ .Release.Name }}
          - name: shm
            hostPath:
              path: /dev/shm
              type: Directory
          {{- $pv_index := 1 }}
          {{- range $pv := .Values.pvc }}
          - name: pv-{{ $pv_index }}
            persistentVolumeClaim:
              claimName: {{ $pv.name }}
          {{- $pv_index = add $pv_index 1 }}
          {{- end }}
          tolerations:
          {{- range $v := .Values.tolerations }}
            - key: {{ tpl $v.key  $ }}
              {{- if $v.operator }}
              operator: "{{ $v.operator }}"
              {{- end }}
              {{- if $v.effect }}
              effect: "{{ $v.effect }}"
              {{- end }}
          {{- end }} 
          nodeSelector:
            node.kubernetes.io/instance-type: {{ .Values.resources.node_type }}
          containers:
            - name: pytorch
              env:
              {{- range $v := .Values.train.env }}
              - name: {{ $v.name }}
                value: "{{ tpl $v.value $ }}"
              {{- end }} 
              command: 
              - /etc/config/train-script.sh
              resources:
                requests:
                {{- range $k, $v := .Values.resources.requests }}
                  {{ $k }}: {{ $v }}
                {{- end }}
                limits:
                {{- range $k, $v := .Values.resources.limits }}
                  {{ $k }}: {{ $v }}
                {{- end }}
              image: {{ .Values.image }}
              imagePullPolicy: IfNotPresent
              volumeMounts:
                - mountPath: /etc/config
                  name: config
                - mountPath: /dev/shm
                  name: shm
                {{- $pv_index := 1 }}
                {{- range $pv := .Values.pvc }}
                - mountPath: {{ $pv.mount_path }}
                  name: pv-{{ $pv_index }}
                {{- $pv_index = add $pv_index 1 }}
                {{- end }}
    {{- end }}